%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Journal Article
% LaTeX Template
% Version 1.3 (9/9/13)
%
% This template has been downloaded from:
% http://www.LaTeXTemplates.com
%
% Original author:
% Frits Wenneker (http://www.howtotex.com)
%
% License:
% CC BY-NC-SA 3.0 (http://creativecommons.org/licenses/by-nc-sa/3.0/)
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%----------------------------------------------------------------------------------------
%	PACKAGES AND OTHER DOCUMENT CONFIGURATIONS
%----------------------------------------------------------------------------------------
\documentclass[twoside]{article}

\usepackage{mathtools}
\usepackage{amsmath}

\usepackage{graphicx}
\graphicspath{ {figures/} }

\usepackage[usenames,dvipsnames]{color} % Required for specifying custom colors and referring to colors by name

\definecolor{MyRed}{rgb}{0.6, 0.0, 0.0} 
\definecolor{MyGreen}{rgb}{0.0,0.4,0.0} % Comment color
\definecolor{MyBlue}{rgb}{0.0, 0.0, 0.6}

%\setlength\parindent{24pt}

\usepackage[pdftex]{hyperref} % For hyperlinks in the PDF
\hypersetup{
  colorlinks=true,
  linkcolor=MyBlue, 
  citecolor=MyRed,
  urlcolor= MyGreen
}

% make hyperlinks bold
\newcommand{\aref}[1]
 {\textbf{\autoref{#1}}}

\newcommand{\nref}[1]
 {\textbf{\nameref{#1}}}

\newcommand{\cc}[1]
 {\textbf{\cite{#1}}}

\usepackage{lipsum} % Package to generate dummy text throughout this template

\usepackage[sc]{mathpazo} % Use the Palatino font
\usepackage[T1]{fontenc} % Use 8-bit encoding that has 256 glyphs
\linespread{1.05} % Line spacing - Palatino needs more space between lines
\usepackage{microtype} % Slightly tweak font spacing for aesthetics

\usepackage[hmarginratio=1:1,top=32mm,columnsep=20pt]{geometry} % Document margins
\usepackage{multicol} % Used for the two-column layout of the document
\usepackage[hang, small,labelfont=bf,up,textfont=it,up]{caption} % Custom captions under/above floats in tables or figures
\usepackage{booktabs} % Horizontal rules in tables
\usepackage{float} % Required for tables and figures in the multi-column environment - they need to be placed in specific locations with the [H] (e.g. \begin{table}[H])
\usepackage{hyperref} % For hyperlinks in the PDF

\usepackage{lettrine} % The lettrine is the first enlarged letter at the beginning of the text
\usepackage{paralist} % Used for the compactitem environment which makes bullet points with less space between them

\usepackage{abstract} % Allows abstract customization
\renewcommand{\abstractnamefont}{\normalfont\bfseries} % Set the "Abstract" text to bold
\renewcommand{\abstracttextfont}{\normalfont\small\itshape} % Set the abstract itself to small italic text

\usepackage{titlesec} % Allows customization of titles
%\renewcommand\thesection{\Roman{section}} % Roman numerals for the sections
%\renewcommand\thesubsection{\Roman{subsection}} % Roman numerals for subsections
\titleformat{\section}[block]{\large\scshape\centering}{\thesection.}{1em}{} % Change the look of the section titles
\titleformat{\subsection}[block]{\large}{\thesubsection.}{1em}{} % Change the look of the section titles


%----------------------------------------------------------------------------------------
%	TITLE SECTION
%----------------------------------------------------------------------------------------

\title{\vspace{-15mm}\fontsize{24pt}{10pt}\selectfont\textbf{Article Title}} % Article title

\author{
\large
\textsc{Evan Miller}\\[2mm] 
\textsc{Kiran Vodrahalli}\\[2mm]
\textsc{Albert Lee}\\[2mm]
\vspace{-5mm}
}
\date{January 13, 2015}

%----------------------------------------------------------------------------------------

\begin{document}

\maketitle % Insert title

%----------------------------------------------------------------------------------------
%	ABSTRACT
%----------------------------------------------------------------------------------------

\begin{abstract}

\noindent \lipsum[1] % Dummy abstract text

\end{abstract}

%----------------------------------------------------------------------------------------
%	ARTICLE CONTENTS
%----------------------------------------------------------------------------------------

\begin{multicols}{2} % Two-column layout throughout the main article text

\section{Introduction} \label{sec:Intro}

% introduction 
Since its founding in $2006$, Twitter has grown into a corporation dominating a significant
proporition of social media today. In recent years, it has become interesting to analyze tweets
to determine interesting phenomena ranging from the viral spread of news to the detection of earthquakes \cc{Burks:2014}. The volume of existing tweets is prohibitively large for standard methods of analysis, and requires approaches that are able to either store large amounts of data in memory for fast access (including parallel approaches to data processing) or approaches that only require sublinear memory while retaining accuracy guarantees. In this paper, we investigate a problem utilizing the latter method. 

\subsection{Problem Statement} 

% give clear definition of problem and motivation here
We would like to create an online algorithm for providing a real-time estimate of the frequencies of hashtags on Twitter time series data.

why we don't use raw frequency counts for the past hour:
there are some hashtags that are constantly present (for example, $\#$porn, $\#$gamesinsight, $\#$teamfollowback (a way to get Twitter followers fast))
these should not be counted as 'trending', so we need to filter these out
with the history. what remains is 'what is trending'

Furthermore, our estimate should not require the entire history of tweets 

Essentially, we must estimate a probability distribution for a finite set of labels in some moving time window of fixed size. Our labels will be Twitter hashtags, and we will take the window size to be 3 hours.
Our aim will be to approximate the k most popular Twitter hashtags in the past 3 hours in order to tell what is trending.

The idea is that estimating the top $k$ hashtags in some time interval provides a model for the topics that are trending on Twitter in that time period.


\subsection{Previous Work}

% describe past work in the areas here

Some approaches attempt to do this by storing all of the frequency data, and looking at recent spikes while conditioning on all of the past frequency data in order to determine estimates of trending likelihood. We would like to improve the space complexity of this solution. Our approach will differ in that we will not store all the data of the past, but instead use several Count-Min Sketches to approximate the past frequencies. 

As a preliminary starting point for approximating the past frequencies, we will utilize concepts from 'Hokusai -- Sketching Streams in Real Time' (Matusevych et al., 2012) to generalize the Count-Min Sketch scheme to time-series data. The rough idea behind this approach is that in the distant past, we should only care about heavy-hitters, i.e. hashtags with high frequencies in order to estimate the likelihood that the hashtag is trending again.

\subsection{Our Approach}


We will store the exact counts for the present (3 hour window), and continuously update the past and present as new data streams in. As a side note, we plan to represent the rolling 3-hour window of frequencies as a discrete approximation: we have a bucket for every second, and update the count of the bucket in every second. When the second passes, we appropriate the bucket that represents the oldest second (i.e. 180 seconds ago) for the newest second, and thus maintain a rolling window across time for exact frequency counts in the past 3 minutes. This rolling window will be denoted as the present.

The baseline comparison for our performance will be the naive version of frequency tallying -- we will keep track of the entire history of frequencies, and will use the past to inform the present probability as to whether or not a given hashtag is trending. We also plan to provide a graphic of the top k hashtags, with histogram changing in real time as the estimated frequencies change. Regarding the data, we would ideally gain access to Twitter's firehose of tweets (as only a small subset of the true data is provided for those without access). 
%------------------------------------------------

\section{Describing the Algorithm}

% to note: our goal was to make a real time query algorithm that USES
% the history (in condensed form) to help understand current time 
% we're remembering the past with less accuracy to save space (realistic model)
% in order to get good estimates of present trending
% this means we are not trying to query the past the way Hokusai is.

% how did we approach it 
\lipsum[1]

\subsection{Data Structures}
% -- we maintain datastructure in two parts: History, and Present
\lipsum[2-3] % Dummy text

\subsection{Algorithm Pseudocode} 

\lipsum[4] % Dummy text

%------------------------------------------------

\section{Analyzing the Algorithm}

\lipsum[1]

\subsection{Correctness}

\lipsum[2-3]

\subsection{Spatial Analysis}

\lipsum[2-3]

\subsection{Runtime Analysis}

\lipsum[2-3]

%------------------------------------------------

\section{Design Choices}

\lipsum[1]

%------------------------------------------------

\section{Results}


\lipsum[5] % Dummy text

\begin{equation}
\label{eq:emc}
e = mc^2
\end{equation}

\lipsum[6] % Dummy text

%------------------------------------------------

\section{Discussion}

\lipsum[7] % Dummy text

%------------------------------------------------
\section{Future Work} \label{sec:Future Work}

Given enough time, another data stream of interest could be Wikipedia edits -- our goal would be to estimate which Wikipedia topics are being edited the most at any given time interval of 3 hours (though we could shrink this to smaller times). As a final sidenote, another application of this algorithm/ data structure would be to estimate the hottest selling stocks on Wall St. Of course this would require a firehose data stream to Wall St., and as that is not as easily obtainable as say, Twitter data, we only mention it as another useful application.

\section{Appendix I: Code} \label{sec:Appendix_code}

We provide links to \href{https://github.com/kiranvodrahalli/cos521/}{all our code}.

\end{multicols}

%----------------------------------------------------------------------------------------
%	REFERENCE LIST
%----------------------------------------------------------------------------------------

\begin{thebibliography}{99} % Bibliography - this is intentionally simple in this template


\bibitem[Burks2014]{Burks:2014}
Burks, L., Miller, M., and Zadeh, R. (2014). 
\newblock RAPID ESTIMATE OF GROUND SHAKING INTENSITY BY COMBINING SIMPLE EARTHQUAKE CHARACTERISTICS WITH TWEETS. 
\newblock {\em Tenth U.S. National Conference on Earthquake Engineering Frontiers of Earthquake Engineering}. Retrieved from \href{http://www.stanford.edu/~rezab/papers/eqtweets.pdf}{http://www.stanford.edu/~rezab/papers/eqtweets.pdf}

\bibitem[Cormode2005]{Cormode:2005}
Cormode, G., and Muthukrishnan, S. (2005). 
\newblock An improved data stream summary: The count-min sketch and its applications. 
\newblock {\em Journal of Algorithms, 55}(1), pp. 58-75.

\bibitem[Matusevych2012]{Matusevych:2012}
Matusevych, S., Smola, A., and Ahmed, A. (2012).
\newblock Hokusai--Sketching Streams in Real Time.
\newblock {\em UAI '12: 28th conference on Uncertainty in Artificial Intelligence}, pp. 594-603.


 
\end{thebibliography}

%----------------------------------------------------------------------------------------



\end{document}
